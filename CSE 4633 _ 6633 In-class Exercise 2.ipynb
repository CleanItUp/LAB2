{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWUoXMRbG7Ykt4tG2bErme"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Markov-Chain Text Generators\n","\n","Markov-Chain Text Generators work based on statistics on which word normally follows another word. Similar concepts are used in many large language models such as GPT3, ChatGPT, and autocomplete / auto-suggestion on smartphone keyboard apps.\n","\n","An open-source implementation can be found here:\n","[https://github.com/jsvine/markovify](https://github.com/jsvine/markovify)"],"metadata":{"id":"6-frn5sKyac-"}},{"cell_type":"markdown","source":["#A: Load a text corpus\n","\n","A text corpus is a large set of texts that is used to train a language model.\n","\n","For now, we will use the text of all Shakespeare's sonnets as our text corpus."],"metadata":{"id":"AaMQDhNA1GdB"}},{"cell_type":"code","source":["# Download the TXT file containing the text corpus\n","!wget https://raw.githubusercontent.com/brunoklein99/deep-learning-notes/master/shakespeare.txt"],"metadata":{"id":"SrKflKwE1Fu7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read the TXT file and store it in a Python string\n","filename = 'shakespeare.txt'\n","corpus = open(filename, 'r').read()\n","print('Loaded %d bytes from %s' % (len(corpus), filename))"],"metadata":{"id":"mf3akSuM0_5k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# B. Pre-processing and cleaning"],"metadata":{"id":"5SbukqzwXTKT"}},{"cell_type":"code","source":["# Since certain punctuation marks have special meaning,\n","# we need to split them when they are attached to words.\n","# This can be done by adding a space.\n","corpus = corpus.replace(',', ' ,')\n","corpus = corpus.replace('.', ' .')"],"metadata":{"id":"wPJxqn4bXXac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replace certain punctuation as commas and others as periods\n","corpus = corpus.replace(':', ' ,')\n","corpus = corpus.replace(';', ' ,')\n","corpus = corpus.replace('?', ' .')\n","corpus = corpus.replace('!', ' .')"],"metadata":{"id":"Ipj82bRrfyRv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove unwanted punctuation\n","corpus = corpus.replace('(', '')\n","corpus = corpus.replace(')', '')"],"metadata":{"id":"D8FfT-68tF9S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now we can use the split() function to split the string\n","# into a list of individual words\n","words = corpus.split()\n","print('Found %d words' % len(words))"],"metadata":{"id":"75GAC3NvWMct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert all words into lowercase characters\n","words = [w.lower() for w in words]"],"metadata":{"id":"pE363biCXam2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print out the first 20 words\n","print(words[:20])"],"metadata":{"id":"TKZXQSqDXnEN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# C: Build the Markov Chain\n","\n","Builds the Markov model by representing it as a Python dictionary. Returns a dict of dicts where the keys of the outer dict represent all possible states,\n","and point to the inner dicts. The inner dicts represent all possibilities\n","for the \"next\" item in the chain, along with the count of times it appears in the text corpus.\n","\n","Beginning and end of sentences are indicated by the `'.'` character"],"metadata":{"id":"5Ak6Bgsz2bwp"}},{"cell_type":"code","source":["# TODO: implement a function that builds the markov chain\n","# iterate through the input list of words and for each index i,\n","# increment model[words[i]][words[i+1]] by one\n","\n","def build_markov_chain(words):\n","    # Markov chain model is represented as a Python dictionary of counts\n","    model = {}\n","\n","    # remember to map '.' to the first word since it is the\n","    # beginning of a sentence\n","\n","    return model"],"metadata":{"id":"h4k_fc4e2ohm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = build_markov_chain(words)\n","print('Built a Markov chain model with %d unique words' % len(model))"],"metadata":{"id":"AXi1Xg4ydBHw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model['quick'])\n","# should return {'fire': 1, 'change': 1, 'objects': 1}"],"metadata":{"id":"7R2XRFJGdFtc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model['many'])\n","# should return {',': 4, 'maiden': 1, 'a': 4, 'lambs': 1, 'gazers': 1, 'nymphs': 1, 'legions': 1}"],"metadata":{"id":"sn-kODI6eoRI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# shows the list of possible words that can be used to start a sentence\n","print(model['.'])"],"metadata":{"id":"rPvWdVvDeet1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: implement a function that computes the probability\n","#   distribution over all possible next words from a given current word\n","#   and stores it in a dictionary 'model_probs'\n","#   For any word in the corpus, model_probs should map it to a tuple containing\n","#   a list of the next word options and a list of the associated probabilities\n","\n","def compute_probability_distribution(model):\n","    model_probs = {}\n","\n","    return model_probs"],"metadata":{"id":"A5LtQ22khyAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_probs = compute_probability_distribution(model)\n","print('Computed the probability distribution for %d words' % len(model_probs))"],"metadata":{"id":"gwpoM2fUjNbT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model_probs['quick'])\n","# should return (['fire', 'change', 'objects'], [0.3333333333333333, 0.3333333333333333, 0.3333333333333333])"],"metadata":{"id":"Obx0nRXZjdoQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model_probs['many'])\n","# should return ([',', 'maiden', 'a', 'lambs', 'gazers', 'nymphs', 'legions'], [0.3076923076923077, 0.07692307692307693, 0.3076923076923077, 0.07692307692307693, 0.07692307692307693, 0.07692307692307693, 0.07692307692307693])"],"metadata":{"id":"2AQ219TXjlfW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# D. Generating Text"],"metadata":{"id":"1T_N2WXrkDqZ"}},{"cell_type":"code","source":["# TODO: implement a function that randomly generates the next word\n","#       given a Markov chain model and a specified current word\n","# Hint: use the function numpy.random.choice, which\n","#       draws a random sample from a discrete distribution\n","# e.g. np.random.choice(['a', 'b', 'c'], p=[0.2, 0.3, 0.5])\n","#       returns either 'a', 'b', or 'c' with probability 0.2, 0.3, 0.5 respectively\n","import numpy as np\n","def generate_next_word(model_probs, current_word):\n","    return ''"],"metadata":{"id":"oPpKB3zenUke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(generate_next_word(model_probs, 'quick'))\n","# should randomly return either fire, change, or objects"],"metadata":{"id":"HN30qfvGnmx4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: implement a function that randomly generates a phrase\n","#       starting with the beginning of sentence symbol ('.')\n","#       continue generating words until either ',' or '.' is encountered\n","\n","def generate_phrase(model_probs):\n","    return ''\n"],"metadata":{"id":"VQKZg-2RomCf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(generate_phrase(model_probs))\n","# should return a phrase ending in either ',' or '.'"],"metadata":{"id":"lZ94ESwdqGjQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: implement a function that randomly generates a sonnet\n","#       in the style of Shakespeare.\n","#       A sonnet is a poem with 14 lines.\n","#       Remember to capitalize the first letter of each sentence\n","#       and add punctuation in appropriate locations.\n","#       Filter out phrases that are too long or too short\n","#       The rhyming scheme may be ignored for this function.\n","\n","def generate_sonnet(model_probs):\n","    return ''"],"metadata":{"id":"Smm9Qx98pcrl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(generate_sonnet(model_probs))"],"metadata":{"id":"FOOhI-57rWz0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# E. Using a different corpus\n","\n","Let's try using a dataset of user reviews of electronic items on Amazon.com\n","as our text corpus"],"metadata":{"id":"ErQpHkltkqID"}},{"cell_type":"code","source":["!wget -O amazon.json \"https://datasets-server.huggingface.co/first-rows?dataset=amazon_us_reviews&config=Electronics_v1_00&split=train\""],"metadata":{"id":"J3I99M7vj_Bl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the JSON library to parse the text data\n","import json\n","filename = 'amazon.json'\n","data = json.load(open(filename, 'r'))\n","print('Found %d lines of data in %s' % (len(data['rows']), filename))"],"metadata":{"id":"WacOViy5uPMP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pre-processing and cleaning\n","corpus = ''\n","for row in data['rows']:\n","    line = row['row']['review_body']\n","    if not line[-1] == '.':\n","        line += '.'\n","    corpus += line + ' '\n","\n","corpus = corpus.replace(',', ' ,')\n","corpus = corpus.replace('.', ' .')\n","corpus = corpus.replace('<br />', '')\n","corpus = corpus.replace('(', '')\n","corpus = corpus.replace(')', '')\n","\n","words = corpus.split()\n","words = [w.lower() for w in words]\n","print('Found %d words' % len(words))\n","print(words[:20])"],"metadata":{"id":"AB8PQCazvT87"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Build a Markov chain and generate a random phrase\n","#       The result should read like a random Amazon review\n"],"metadata":{"id":"qIfYRBMtww5d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# F. Generate your own text\n","\n","Experiment with the code in this notebook to create your own AI language model for text generation. By changing different parameters such as the state size, punctuation rules, language rules, and source of text corpus, you can create many different types of language models.\n","\n","Some ideas to try:\n","\n","*   Presidential speech generator\n","*   Poetry generator\n","*   Twitter post generator\n","*   Movie script generator\n","*   Cake recipe generator\n"],"metadata":{"id":"-eROo5ADk_MY"}},{"cell_type":"markdown","source":["# Helpful resources/libraries for Natural Language Processing\n","\n","1.   [spaCy](https://spacy.io/)\n","2.   [NLTK](https://www.nltk.org/)\n","3.   [NLTK datasets](https://www.nltk.org/nltk_data/)\n","4.   [HuggingFace datasets](https://huggingface.co/datasets)\n","\n"],"metadata":{"id":"dZ-n-WM1QPdC"}}]}